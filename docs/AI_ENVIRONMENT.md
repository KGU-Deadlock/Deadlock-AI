## 1. 개요 (Overview)
- 본 문서는 사용자의 음성 데이터를 실시간으로 처리하기 위한 AI 인프라 구성 및 런타임 환경에 대해 기술함.
- 전용 GPU 서버 구축 대신 **가속 추론 API(LPU)**와 **분산 미디어 서버(SFU)**를 활용하여 다중 사용자 환경에서도 안정적인 성능을 확보하는 것을 목표로 함.

## 2. AI 인프라 및 통신 환경 비교 분석
실시간 인터렉션의 품질을 결정하는 핵심 기술 지표를 확인함.

비교 항목 | Standard Cloud API | Local Server (Whisper) | LPU Optimized API (Selected)
-- | -- | -- | --
**추론 지연 시간** | 인터넷망 상태에 따라 상이 | 로컬 사양(VRAM)에 종속 | **실시간 (Groq LPU 가속)**
**한국어 인식률** | 양호 | 보통 (모델 크기 의존) | **우수 (Whisper v3 Turbo)**
**동시 접속성** | 순차 처리 위주 | GPU 병목 가능성 높음 | **병렬 추론 최적화**
**운영 난이도** | 낮음 | 매우 높음 (CUDA 설정 등) | **낮음 (API 기반 통합)**
**도입 비용** | 사용량 대비 높음 | 고사양 GPU 구매/임대료 발생 | **무료 티어 기반 저비용**


## 3. AI 환경 구축 핵심 사유

### 3.1. 저지연 음성 인터렉션 파이프라인
- **Groq LPU 기반 Whisper v3 도입:** 기존 GPU 추론의 한계를 해결한 LPU(Language Processing Unit) 인프라를 통해, 음성 인식 대기 시간을 1초 미만으로 단축하여 실제 대화와 유사한 사용자 경험을 제공함.
- **Real-time Pipeline:** 사용자가 말을 마치는 즉시 텍스트로 변환되어 LLM으로 전달되는 고속 추론 체계를 구축함.

### 3.2. 인식 정확도 보완 및 다중화
- **ETRI 공공 AI API 통합:** 전문적인 CS 기술 용어의 정확한 인식을 위해 한국어 특화 데이터가 풍부한 국산 엔진을 이중화하여, Whisper 모델에서 발생할 수 있는 기술 용어 오인식 리스크를 최소화시킴.

### 3.3. 다자간 실시간 통신 및 에이전트 연동 (다대다 모의 면접)
- **LiveKit SFU 아키텍처 채택:** 다대다 모의면접 환경을 지원하기 위해 클라이언트 부하를 최소화하는 SFU 방식을 도입하고, AI 면접관을 실시간 미디어 트랙 참여자로 연동하여 발화자 식별 및 개별 피드백 기능 구현 예정.
